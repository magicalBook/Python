{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facial emotion recognition in image\n",
    "#print all emotion accuracy\n",
    "#wan cheng de dai ma\n",
    "#tou ming te xiao\n",
    "#using PIL Draw\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "emotion = {0 : 'Angry',\n",
    "           1 : 'Disgust',\n",
    "           2 : 'Fear',\n",
    "           3 : 'Happy',\n",
    "           4 : 'Normal',\n",
    "           5 : 'Sad',\n",
    "           6 : 'Surprise'}\n",
    "\n",
    "path = 'C:\\\\Users\\\\CHENTIEJUN\\\\Desktop\\\\tt'\n",
    "imgPath = os.path.join(path,'19.png')\n",
    "outPath = os.path.join(path,'19_integrationDataset.png')\n",
    "\n",
    "modelPath = 'E:\\\\network\\\\inceptionV3\\\\models\\\\inceptionV3_integrationDataset.h5'\n",
    "\n",
    "detector = MTCNN()\n",
    "model = load_model(modelPath)\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(imgPath),cv2.COLOR_BGR2RGB)\n",
    "image_copy = image.copy()\n",
    "img = detector.detect_faces(image)\n",
    "\n",
    "box = img[0]['box']\n",
    "cropped = image[box[1]:box[1]+box[3],box[0]:box[0]+box[2]]\n",
    "\n",
    "x = cv2.resize(cropped,(200,150),interpolation = cv2.INTER_AREA)\n",
    "x = img_to_array(x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255\n",
    "    \n",
    "custom = model.predict(x)\n",
    "maxIndex = np.argmax(custom)\n",
    "\n",
    "mask_width = 130\n",
    "box_height = 180\n",
    "#font = cv2.LINE_AA\n",
    "font = ImageFont.truetype('arial.ttf',15)\n",
    "font_1 = ImageFont.truetype('arial.ttf',20)\n",
    "_,img_width = image.shape[:2]\n",
    "\n",
    "cv2.rectangle(image,(box[0],box[1]),(box[0]+box[2],box[1]+box[3]),(67,116,217),1)\n",
    "\n",
    "points = np.array([[box[0]+box[2]+5,box[1]],\n",
    "                   [box[0]+box[2]+5+mask_width,box[1]],\n",
    "                   [box[0]+box[2]+5+mask_width,box[1]+box_height],\n",
    "                   [box[0]+box[2]+5,box[1]+box_height]],np.int32)\n",
    "\n",
    "sub_img = image_copy[box[1]:box[1]+box_height,box[0]+box[2]+5:box[0]+box[2]+5+mask_width]\n",
    "roi = image[box[1]:box[1]+box_height,box[0]+box[2]+5:box[0]+box[2]+5+mask_width]\n",
    "\n",
    "if (box[0]+box[2]+5+mask_width) > img_width:\n",
    "    points = np.array([[box[0]+box[2]+5,box[1]],\n",
    "                       [box[0]+box[2]+5+img_width,box[1]],\n",
    "                       [box[0]+box[2]+5+img_width,box[1]+box_height],\n",
    "                       [box[0]+box[2]+5,box[1]+box_height]],np.int32)\n",
    "\n",
    "    sub_img = image_copy[box[1]:box[1]+box_height,box[0]+box[2]+5:box[0]+box[2]+5+img_width]\n",
    "    roi = image[box[1]:box[1]+box_height,box[0]+box[2]+5:img_width]\n",
    "    \n",
    "background = cv2.fillConvexPoly(image,points,(76,76,76))\n",
    "\n",
    "dst = cv2.addWeighted(roi,0.5,sub_img,0.5,0)\n",
    "\n",
    "background[points[0][1]:points[2][1],points[0][0]:points[2][0]] = dst\n",
    "background = Image.fromarray(background)\n",
    "draw = ImageDraw.Draw(background)\n",
    "\n",
    "#cv2.putText(background,'Emotion:',(box[0]+box[2]+7,box[1]+15),font,0.6,(255,255,255),2,font)\n",
    "draw.text((box[0]+box[2]+7,box[1]), 'Emotion:', font=font_1, fill=(255,255,255))\n",
    "distance = 20\n",
    "for i in range(len(emotion)):\n",
    "    if i == maxIndex:\n",
    "        #cv2.putText(background,emotion[i]+f':{custom[0][i] : .2%}',(box[0]+box[2]+9,box[1]+distance+15),font,0.5,(255,228,0),1,font)\n",
    "        draw.text((box[0]+box[2]+9,box[1]+distance+15), emotion[i]+f':{custom[0][i] : .2%}', font=font, fill=(255,228,0))\n",
    "    else:\n",
    "        #cv2.putText(background,emotion[i]+f':{custom[0][i] : .2%}',(box[0]+box[2]+9,box[1]+distance+15),font,0.5,(255,255,255),1,font)    \n",
    "        draw.text((box[0]+box[2]+9,box[1]+distance+15), emotion[i]+f':{custom[0][i] : .2%}', font=font, fill=(255,255,255))\n",
    "    distance += 21\n",
    "\n",
    "background = cv2.cvtColor(np.array(background),cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow('result',background)\n",
    "cv2.imwrite(outPath,background)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facial emotion recognition in Video\n",
    "#tou ming xiao guo\n",
    "#using PIL\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "emotion = {0 : 'Angry',\n",
    "           1 : 'Disgust',\n",
    "           2 : 'Fear',\n",
    "           3 : 'Happy',\n",
    "           4 : 'Normal',\n",
    "           5 : 'Sad',\n",
    "           6 : 'Surprise'}\n",
    "\n",
    "path = 'D:\\Camera_data'\n",
    "videoName = 'depthCam_Driver_10_10_23_59_31'\n",
    "\n",
    "inputVideoPath = os.path.join(path,videoName)+'.avi'\n",
    "outputVideoPath = path+'\\\\result'+videoName+'.avi'\n",
    "\n",
    "modelPath = 'E:\\\\network\\\\inceptionV3\\\\models\\\\inceptionV3_integrationDataset.h5'\n",
    "\n",
    "detector = MTCNN()\n",
    "model = load_model(modelPath)\n",
    "\n",
    "capture = cv2.VideoCapture(inputVideoPath)\n",
    "\n",
    "fps = int(round(capture.get(cv2.CAP_PROP_FPS)))\n",
    "\n",
    "\n",
    "width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(outputVideoPath,fourcc,fps,(width,height))\n",
    "\n",
    "averageAccuracy = np.array([[0,0,0,0,0,0,0]])\n",
    "flag = True\n",
    "while flag:\n",
    "    totalAccuracy = np.zeros((1,7))\n",
    "    imageNum = 0\n",
    "    for i in range(fps):\n",
    "        ret,frame = capture.read()\n",
    "        if not ret:\n",
    "            flag = False\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        frame_copy = frame.copy()\n",
    "        \n",
    "        face = detector.detect_faces(frame)\n",
    "        \n",
    "        if not face:\n",
    "            continue\n",
    "\n",
    "        boxList = np.zeros(len(face))\n",
    "        for i in range(len(face)):\n",
    "            box = face[i]['box']\n",
    "            boxList[i] = box[2]*box[3]\n",
    "\n",
    "        maxBoxIndex = np.argmax(boxList)\n",
    "        maxBox = face[maxBoxIndex]['box']\n",
    "\n",
    "        cropped = frame[maxBox[1]:maxBox[1]+maxBox[3],maxBox[0]:maxBox[0]+maxBox[2]]\n",
    "        \n",
    "        x = cv2.resize(cropped,(200,150),interpolation = cv2.INTER_AREA)\n",
    "        x = img_to_array(x)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x /= 255\n",
    "\n",
    "        custom = model.predict(x)\n",
    "        \n",
    "        mask_width = 130\n",
    "        _,img_width = frame.shape[:2]\n",
    "        box_height = 180\n",
    "        #font = cv2.LINE_AA\n",
    "        font = ImageFont.truetype('arial.ttf',15)\n",
    "        font_1 = ImageFont.truetype('arial.ttf',20)\n",
    "\n",
    "        cv2.rectangle(frame,(box[0],box[1]),(box[0]+box[2],box[1]+box[3]),(67,116,217),1)\n",
    "\n",
    "        points = np.array([[box[0]+box[2]+5,box[1]],\n",
    "                               [box[0]+box[2]+5+mask_width,box[1]],\n",
    "                               [box[0]+box[2]+5+mask_width,box[1]+box_height],\n",
    "                               [box[0]+box[2]+5,box[1]+box_height]],np.int32)\n",
    "\n",
    "        sub_img = frame_copy[box[1]:box[1]+box_height,box[0]+box[2]+5:box[0]+box[2]+5+mask_width]\n",
    "        roi = frame[box[1]:box[1]+box_height,box[0]+box[2]+5:box[0]+box[2]+5+mask_width]\n",
    "        if (box[0]+box[2]+5+mask_width) > img_width:\n",
    "            points = np.array([[box[0]+box[2]+5,box[1]],\n",
    "                               [box[0]+box[2]+5+img_width,box[1]],\n",
    "                               [box[0]+box[2]+5+img_width,box[1]+box_height],\n",
    "                               [box[0]+box[2]+5,box[1]+box_height]],np.int32)\n",
    "\n",
    "            sub_img = frame_copy[box[1]:box[1]+box_height,box[0]+box[2]+5:box[0]+box[2]+5+img_width]\n",
    "            roi = frame[box[1]:box[1]+box_height,box[0]+box[2]+5:img_width]\n",
    "\n",
    "        background = cv2.fillConvexPoly(frame,points,(76,76,76))\n",
    "\n",
    "        dst = cv2.addWeighted(roi,0.5,sub_img,0.5,0)\n",
    "\n",
    "        background[points[0][1]:points[2][1],points[0][0]:points[2][0]] = dst\n",
    "        \n",
    "        background = Image.fromarray(background)\n",
    "        draw = ImageDraw.Draw(background)\n",
    "\n",
    "        totalAccuracy += custom\n",
    "        imageNum += 1\n",
    "        \n",
    "        if (imageNum != 0 and imageNum % 20 == 0):\n",
    "            averageAccuracy = totalAccuracy / imageNum\n",
    "            print(averageAccuracy)\n",
    "            \n",
    "        #cv2.rectangle(background,(box[0],box[1]),(box[0]+box[2],box[1]+box[3]),(103,153,255),1)\n",
    "\n",
    "        draw.text((box[0]+box[2]+7,box[1]), 'Emotion:', font=font_1, fill=(255,255,255))\n",
    "        \n",
    "        maxIndex = np.argmax(averageAccuracy)\n",
    "        distance = 20\n",
    "        \n",
    "        if np.sum(averageAccuracy)==0:\n",
    "            #cv2.putText(background,'Recognizing...',(box[0]+box[2]+9,box[1]+(box_height//2)),font,0.6,(255,228,0),1,cv2.LINE_AA)\n",
    "            draw.text((box[0]+box[2]+9,box[1]+(box_height//2)), 'Recognizing...', font=font_1, fill=(255,228,0))    \n",
    "        else:\n",
    "            for i in range(len(emotion)):\n",
    "                if i == maxIndex:\n",
    "                    #cv2.putText(background,emotion[i]+f':{averageAccuracy[0][i] : .2%}',(box[0]+box[2]+7,box[1]+distance+15),font,0.5,(255,228,0),1,cv2.LINE_AA)\n",
    "                    draw.text((box[0]+box[2]+7,box[1]+distance+15), emotion[i]+f':{averageAccuracy[0][i] : .2%}', font=font, fill=(255,228,0))\n",
    "                else:\n",
    "                    #cv2.putText(background,emotion[i]+f':{averageAccuracy[0][i] : .2%}',(box[0]+box[2]+7,box[1]+distance+15),font,0.5,(255,255,255),1,cv2.LINE_AA)    \n",
    "                    draw.text((box[0]+box[2]+7,box[1]+distance+15), emotion[i]+f':{averageAccuracy[0][i] : .2%}', font=font, fill=(255,255,255))\n",
    "                distance += 21\n",
    "\n",
    "        background = cv2.cvtColor(np.array(background),cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('result',background)\n",
    "        out.write(background)\n",
    "    \n",
    "    key = cv2.waitKey(3)\n",
    "    if key == 27:\n",
    "        break\n",
    "        print('ese break...')\n",
    "        \n",
    "capture.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
